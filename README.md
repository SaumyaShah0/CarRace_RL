
# ğŸš— CarRacing-v3 Reinforcement Learning Agent  
### **PPO + Stable-Baselines3 | Gymnasium | PyTorch | CUDA Accelerated**

This project trains a deep reinforcement learning agent using **Proximal Policy Optimization (PPO)** to play the **CarRacingâ€‘v3** environment from **Gymnasium**.  
The environment provides a topâ€‘down racing track where the agent must learn steering, braking, and acceleration to complete laps efficiently.

---

## â­ Key Features

- **PPO with CNN-based policy**
- **Vectorized environment** for faster training
- **GPU acceleration (CUDA)**
- **Checkpoint saving + best model tracking**
- **Evaluation script with rendering**
- **Training logs compatible with TensorBoard**
- **Clean project structure for GitHub**

---

## ğŸ“‚ Project Structure

```
Car_Race/
â”‚
â”œâ”€â”€ train_agent.py         # Training script
â”œâ”€â”€ eval_agent.py          # Evaluate trained model
â”œâ”€â”€ env_test.py            # Quick environment test
â”‚
â”œâ”€â”€ requirements.txt       # Dependencies list
â”œâ”€â”€ .gitignore             # Git ignore rules
â””â”€â”€ README.md              # Project documentation
```

---

## ğŸš€ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/your-username/car-race-ppo.git
cd car-race-ppo
```

### 2ï¸âƒ£ Create and activate virtual environment  
**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸï¸ Environment Details â€” CarRacingâ€‘v3

- Observation shape: **(96, 96, 3)** RGB image  
- Action space: **[steer, gas, brake]**  
- Continuous control  
- Randomly generated track (different layout every episode)

---

## ğŸ‹ï¸ Training the PPO Agent

Simply run:

```bash
python train_agent.py
```

What this script does:

âœ” Creates vectorized + monitored environments  
âœ” Trains PPO for 1M timesteps  
âœ” Saves:
- `logs_car_race/best_model/best_model.zip`
- TensorBoard logs  
- Checkpoints  

---

## ğŸ“Š Monitoring Training

Start TensorBoard:

```bash
tensorboard --logdir logs_car_race/
```

Open in browser:  
ğŸ‘‰ http://localhost:6006/

You'll see:
- episode rewards  
- policy/value losses  
- learning rate  
- explained variance  

---

## ğŸ® Evaluating the Trained Agent

```bash
python eval_agent.py
```

The script will:

âœ” Load **best_model.zip**  
âœ” Render real-time racing  
âœ” Print reward per episode  

---

## ğŸ¥ Recording Gameplay (Optional)

To generate video:

```python
env = gym.make("CarRacing-v3", render_mode="rgb_array")
```

and use `imageio` or `moviepy` to create MP4 output.

---

## ğŸ“ˆ Example Results (From a 1M-Step PPO Run)

| Metric | Value |
|-------|--------|
| Average Evaluation Reward | **850â€“900** |
| Max Reward | **> 950** |
| Average Episode Length | ~900â€“1000 frames |

A reward above **800** indicates **expert-level driving** in CarRacingâ€‘v3.

---

## ğŸ“¦ Requirements

```
gymnasium==0.29.1
gymnasium[box2d]==0.29.1
pybox2d
stable-baselines3[extra]
tensorboard
moviepy
imageio[ffmpeg]
numpy
```

---

## ğŸ”§ Troubleshooting

### âš  Box2D installation error?
Use:
```bash
pip install gymnasium[box2d]==0.29.1 pybox2d
```

### âš  â€œCUDA not availableâ€?
Install PyTorch with GPU support from  
https://pytorch.org/get-started/locally/

---

## ğŸ“ License
MIT License.  
Feel free to use, modify, and share.

---

## â¤ï¸ Acknowledgements
- Gymnasium developers  
- Stable-Baselines3 team  
- PyTorch contributors  
- OpenAI for original environment inspirations  

---

## â­ Contribute
PRs are welcome.  
Star the repo â­ if you find it useful!

